{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lyrics are stored as a string in a dataframe that contains other information such as the artist and genre. The lyrics in raw format are those that were returned by a Genius API call. The functions below pre-process these raw lyrics and make them suitable to pass into a NLP model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\james\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lyrics_data(file_name):\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "# Extract the song lyrics from the dataframe\n",
    "def extract_song_lyrics(song_lyrics):\n",
    "    processed_song_lyrics = \"\"\n",
    "    phrase = \"\"\n",
    "    for letter in song_lyrics:\n",
    "        if letter == '[': # Look for opening bracket that marks beginning of verse description\n",
    "            if phrase:\n",
    "                processed_song_lyrics += phrase\n",
    "            phrase = \"\"\n",
    "        elif letter == ']': # Look for closing bracket to mark end of verse description\n",
    "            phrase = \"\"\n",
    "        else:\n",
    "            phrase += letter\n",
    "    processed_song_lyrics += phrase\n",
    "    return processed_song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processes lyrics returned from API call so that they can be passed into model\n",
    "def filter_tokens(lyrics):\n",
    "    final_tokens = []\n",
    "    tokens = list(ngrams(nltk.word_tokenize(lyrics), 1))\n",
    "    tail_idx = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for token in tokens:\n",
    "        word = token[0]\n",
    "        word = word.replace('\"', '')\n",
    "        word = word.replace(\"'\", '')\n",
    "        \n",
    "        word = word.replace('\\d+', '')\n",
    "        word = word.replace('[^\\w\\s]', '')\n",
    "        \n",
    "        if word.lower().islower():\n",
    "            if len(word) == 1 and (word.lower() == 'i' or word.lower() == 'a'):\n",
    "                final_tokens.append(word)\n",
    "                tail_idx += 1\n",
    "            elif word == 're' or len(word) == 1: # Handle contractions\n",
    "                if tail_idx >= 1:\n",
    "                    spliced_word = final_tokens[tail_idx - 1] + \"'\" + word\n",
    "                    final_tokens[tail_idx - 1] = spliced_word\n",
    "                else:\n",
    "                    final_tokens.append(word)\n",
    "                    tail_idx += 1\n",
    "            elif word == 'nt':\n",
    "                if tail_idx >= 1:\n",
    "                    spliced_word = final_tokens[tail_idx - 1] + \"n't\"\n",
    "                    final_tokens[tail_idx - 1] = spliced_word\n",
    "                else:\n",
    "                    final_tokens.append(word)\n",
    "                    tail_idx += 1\n",
    "            else:\n",
    "                new_word = lemmatizer.lemmatize(word)\n",
    "                if tail_idx >= 2: # Try to remove duplicate words over and over\n",
    "                    if new_word != final_tokens[tail_idx - 1] and new_word != final_tokens[tail_idx - 2]:\n",
    "                        final_tokens.append(new_word)\n",
    "                        tail_idx += 1\n",
    "                else:\n",
    "                    final_tokens.append(new_word)\n",
    "                    tail_idx += 1\n",
    "    return \" \".join(final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lyrics_df(lyrics_df):\n",
    "    num_rows = lyrics_df.shape[0]\n",
    "    final_df = []\n",
    "    for r in range(num_rows):\n",
    "        point = {}\n",
    "        single_row = lyrics_df.iloc[r]\n",
    "        artist = single_row.Artist\n",
    "        genre = single_row.Genre\n",
    "        song = single_row.Song\n",
    "        \n",
    "        if artist == 'Cam':\n",
    "            continue\n",
    "        lyrics = single_row.Lyrics\n",
    "        \n",
    "        lyrics = lyrics[1:len(lyrics) - 1]\n",
    "        lyrics = extract_song_lyrics(lyrics)\n",
    "        lyrics = filter_tokens(lyrics)\n",
    "        point['Artist'] = artist\n",
    "        point['Genre'] = genre\n",
    "        point['Song'] = song\n",
    "        point['Lyrics'] = lyrics\n",
    "        final_df.append(point)\n",
    "    final_df = pd.DataFrame(final_df)\n",
    "    final_df.to_csv(\"cleaned_lyrics.csv\", index = False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_data = read_lyrics_data(\"LyricsData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_lyrics_df(lyrics_data)\n",
    "processed_data.to_csv(\"cleaned_lyrics.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
